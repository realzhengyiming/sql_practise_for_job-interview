# 广东联通面试准备

STAR l
牛客网，多看看，STAR这个的准备都是一样的。
先按照这个来进行会带，对 每个项目进行拆分准备。

## 先搞简历

### 情感分析的新闻浏览平台
<b>situation 背景：</b>

+ 赛前我们对社交媒体舆论分析这一块很有兴趣

+ 然后我们决定从身边最容易接触到的媒体入手

+ 于是我们就从新闻媒体开始入手，启动项目

<b>target 目标：</b>

+ 新闻和新闻媒体都提取下来，并且

+ 从新闻以及新闻的评论中 得到情感得分，包括消极/积极/中性等极性

+ 然后使用网站来对处理分析后的数据进行展示。

<b>action 我们做了什么：</b>

+ 从各大常见的新闻媒体中抓取每日新闻以及/评论

+ 使用情感分析算法处理抓取到的数据，获得情感得分

+ 使用了lsmt情感分析算法
  + 使用了谭松波老师的中文文本分类语料 来进行训练
+ 搭建出了用于可视化显示网站来对数据进行分析和展示

<b>result: 结论</b>

+ 最终我们完成了每天对腾讯，网易，搜狐新闻网站进行每日增量新闻抓取的任务。对内容进行去重后每天至少1000以上的新闻入库（特别是腾讯的汽车新闻，每隔个几天会用前几天完全的汽车内容来介绍，然后再改一下日期那种）

+ 也完成了对新闻的发布时间，发布类型，正文数量，正文内容，情感得分等进行分析和可视化展示的目标

+ 最终实现了对多个新闻媒体进行一定程度的舆情监督（情感得分），并且获得了设计大赛省赛二等奖的好成绩。

<b>contribution：贡献</b>

+ 我主要负责各大新闻媒体的每日新闻/评论进行数据抓取，实现了每日对三个大新闻媒体的日增新闻抓取和网站构建和可视化，       然后在我们赛前短暂两周的数据记录中新闻舆论的情调总体而言是积极的，说明那几天国内没发生什么比较不好的事情。然后发现一般关于汽车新闻在内容上重复的比较多，然后体育类的新闻每日又快又多，特别是腾讯的，体育新闻甚至大部分是用ai写的，所以又多又迅速。

+ 并且构建web后端对处理后的数据进行可视化的显示



### 链家租房爬虫分析



<b>situation 背景：</b>

+ 因为想着快要出去找工作了，那就需要了解租房市场的大概情况
+ 于是就想到了可以对租房市场进行一定的分析

+ 然后搜索到链家这个平台有租房，于是就启动了项目 

<b>target 目标：</b>

+ 从链家租房中爬取房源数据
+ 使用python的pandas和可视化库pyecharts来对数据进行可视化分析

<b>action 我们做了什么：</b>

+ 编写了基于scrapy的爬虫，然后抓取了北上广深等主要的一二线城市的租房房源的数据
+ 总共爬取了8w条房源的并保存成csv文件
+ 对房子类型，房子发布时间，房子的面积，房子的价格，房子所属城市，房子朝向等进行了分析

<b>result: 结论</b>

+ 最终得到结论很多，比如租房的价格一年内也是会有波动的，一般都在年前放假的时候房租会降低，然后年后就慢慢回升。按季度看的话就是第一二季度价格比三四季度价格高
+ 然后房屋朝向大部分是向南的，  一直说的坐北朝南还是有道理的
+ 然后北上广深中的租房租价格，广州是最低的，上海是最高的，第二高的是深圳，然后发现杭州的房价也蛮高的，可以体现一个城市的发展水平。
+ 然后深圳和广州的链家租房中租房价格在2000元以下的只占百分之19，而且大部分是合租房类型
+ 然后总体而言确实是房屋租房逐年上涨的，这也和大家收入逐年增加相对应的。

<b>contribution：贡献</b>

+ 项目主要由自己完成，主要分成数据抓取和数据分析两块
+ 数据抓取使用scrapy框架来进行编写
+ 分析使用了pandas和pyecharts库来绘制可视化图表和对数据进行清洗。

<br>

### Django部门服务站点的建立

<b>situation 背景：</b>

+ 当时我在英语爱好者协会学术部做部长，安排活动需要经常发各种文件不易于整理和回看
+ 然后我想着搭建一个站点可以把活动记录起来，这样只要有浏览器就可以随时随地方便回看和改进活动的安排

<b>target 目标：</b>

+ 使用django + mdui前端框架搭建出一个简易的站点用来记录
+ 助理们可以注册，登陆进入网站
+ 可以进行发布活动，评论，签到等功能

<b>action 我们做了什么：</b>

+ 购买服务器
+ 使用django+ mdui来对站点进行开发
+ 签到功能，使用了html5自带的定位来对签到地点进行定位
+ 将开发好的站点部署到服务器上，方便助理们可以随时随地通过浏览器访问

<b>result: 结论</b>

+ 最终部门的活动的可以在站点上进行显示和发布，活动也可以在上面进行签到等操作，方便了部门人员间使用
+ 虽然最后服务器到期后因为自己资金不足停止续费了，不过在做这个站点的过程中我学习到了很多的知识，尝试了新的东西，感觉还是收获很多的。

<b>contribution：贡献</b>

+ 项目主要由自己完成开发， 出于服务协会部门内部服务。
+ 网站主要使用django进行开发，并使用了前端框架mdui来编写前端
+ 然后使用了html5自带的定位api来实现签到功能

<br>

## 数据分析纳米学位学了什么？

+ python语法
+ 使用python进行数据清洗，pandas库的使用。
+ 探索性数据分析EDA
+ 使用matplotlib 进行数据可视化
+ 使用tebleau进行可视化

### <b>这儿也很多坑要填啊，都给忘记了</b>

统计学也要复习才可以





## 统计学的坑也要填上去才可以

+ 数据仓库Hive 面试细节，其他的还是SQL

+ 数据建模(建模的算法要了解多一些)

  + 懂得常见的几个机器学习算法，比如knn，贝叶斯算法等
    + 贝叶斯p(a|b ) = 

+ 优秀的sql能力

+ 数据发掘问题

  + 数据源问题
    + 根据不同的数据原设计不同的
  + 输出埋点数据需求
    + 埋点分析，是网站分析的一种常用的数据采集方法。数据埋点分为初级、中级、高级三种方式。数据埋点是一种良好的私有化部署数据采集方式。
    + 在程序中植入多段统计代码，追踪用户在平台每个界面上的系列行为，事件之间相互独立（如打开商品详情页——选择商品型号——加入购物车——下订单——购买完成）
    + 也就是说 设计数据埋点的植入地方，方便埋点数据的提取。
  + 数据质量需求

  <br>

## 对广东联通数据分析岗的职业规划

### 职位描述：

1.准确搜集客户对数据运营的需求，形成精准，可量化需求报告；
2.协同项目内同事，满足客户需求，以项目验收指标为结果导向；
3.熟悉数据仓库和数据建模的相关技术细节，有优秀的SQL数据独立提取能力；
4.结合数据发掘问题，通过公司线上分析工具制作数据分析报告，针对数据源问题，输出埋点数据需求和数据质量需求。

### 任职要求：

1.2020届全日制普通高等院校本科及以上学历；
2.计算机相关专业，专业成绩排名前30%；
3.精通SQL/Hadoop/Hive/TDW等大数据分析工具，有优秀的SQL数据独立提取能力；
4.掌握PowerBI、Tableau、FineBI中任意一款软件，可建立一套专题数据分析可视化模板；
5.具有良好的学习能力、沟通表达能力、抗压能力等；
6.有运营商、互联网公司实习经历优先，具有计算机相关资质证书优先

<br>

## 可能的提问

#### （1）自我介绍

​         各位面试官好下午好，我叫郑义铭，我是广东石油化工学院计算机专业20届毕业生。在校期间，我通过自学依次学会了python语言，基于python语言Web框架Django.然后是python的手写爬虫，scrapy爬虫框架，还有python的数据分析库numpy,pandas，可视化库matplotlib等。最近一次比较大的项目，是基于情感分析算法的新闻浏览平台，我负责数据抓取模块和数据可视化模块的编写，这次项目也在计算机设计大赛中获得了省赛二等奖的成绩。未来我想从事数据分析相关的工作，于是我来投递了贵公司的数据分岗。

#### （1）对数据分析岗位的理解和职业规划

+ 职能类别：大学/大专应届毕业生储备干部

我的回答：

##### 什么是数据分析岗：

数据分析本身是通过数据来解决问题，问题不限于运营，决策，还是产品开发等。只要最终是利用数据解决问题，那它就是数据分析岗。

### 数据分析岗位是越来越来重要的，无论是运营产品还是决策，都需要

##### 我的职业规划

无论如何首先应该都是先从业务型的数据分析开始，然后根据公司职业晋升路线，再考虑继续从事业务型的数据分析，如数据运营或者从事技术型的如数据挖掘。具体的路线考量会在工作后逐渐确定。

+ 一开始先做业务方面的数据分析
  + 主要是什么什么什么
+ 然后1-3年后

#### （4）秋招为什么没拿到offer？

有拿到offer，但是不是数据分析岗的，于是就没去。再然后就是实习期太忙了，那时候我们学校是早早给我们安排了本地的统一培训性质的实习，要跟着他们一起做项目写后端。所以这个我没写进简历。广东国信工程监理。

#### （5）纳米学位学了什么

主要是数据分析常用工具的使用 和 数据分析思维的培养；

1.用python进行数据清洗

2.用python进行数据分析与可视化操作

3.学习如何使用tableau进行数据分析与可视化操作

4.hive sql ，mysql等

####（6）你会什么模型

1.knn算法，这个可能不算模型

2.k聚类

3.

#### 常见数据挖掘项目的闭环如下：

- 定义问题
- 数据抽取
- 数据清洗
- 特征选取/特征工程
- 数据模型
- 数据验证
- 迭代优化

#### 什么是数据分析的过程：

含数据检验、数据清洗、数据重构，以及数据建模的。目的在于发现有用的信息，有建设性的结论，辅助决策的制定。

数据分析其实可以分为两种：一种类似产品经理，更加注重业务，对业务能力要求比较高。一种偏向数据挖掘，更加注重技术，对算法代码能力要求比较高。



数据仓库是什么：

（1）hive是基于Hadoop的一个数据仓库工具，可以直接使用sql语句来对mapreduce来运行。

（2）hadoop是开源的分布式文件系统，Hadoop实现了一个分布式文件系统(Hadoop Distributed File System),简称HDFS。





数据分析可以在以下四个方面开展工作，所以我希望结合自己的数据分析能力，去挖掘业务的风险点，提升控制风险的能力。

偏业务的数据分析师，一般属于运营部门。不少公司也称数据运营或者商业分析。负责和支撑各部门相关的报表；

建立和优化指标体系；

监控数据的波动和异常，找出问题；

优化和驱动业务，推动数据化运营；

找出可增长的市场或产品优化空间；

输出专题分析报告；

+ 数据运营管理

  + 反馈最新的运营情况，为运营管理提供决策支持，提出营销活动优化和成本控制解决方案。

+ 数据营销

  + 寻找目标用户，发现用户特征，构建用户画像，预测用户行为，对用户进行合理分群，用户偏好预测、用户个性化推荐等。

+ 数据产品  - 研发方面

  + 产品优化
    + 根据数据对用户、产品的营收进行分析。由此得出产品的优化方案
  + 新产品研发
    + 同过数据分析来为企业提供产品的发展方向

+ 大数据平台

  + 搭建大数据平台，大数据基础进行研发和运行维护，提升运行的效率

  